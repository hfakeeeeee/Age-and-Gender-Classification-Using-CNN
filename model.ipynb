{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, Dropout, LayerNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "data = pd.read_csv(\"./AdienceBenchmarkGenderAndAgeClassification/fold_3_data.txt\",sep = \"\\t\" )\n",
    "data1 = pd.read_csv(\"./AdienceBenchmarkGenderAndAgeClassification/fold_1_data.txt\",sep = \"\\t\")\n",
    "data2 = pd.read_csv(\"./AdienceBenchmarkGenderAndAgeClassification/fold_2_data.txt\",sep = \"\\t\")\n",
    "data3 = pd.read_csv(\"./AdienceBenchmarkGenderAndAgeClassification/fold_0_data.txt\",sep = \"\\t\")\n",
    "data4 = pd.read_csv(\"./AdienceBenchmarkGenderAndAgeClassification/fold_4_data.txt\",sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.concat([data, data1, data2, data3, data4], ignore_index=True)\n",
    "print(data.shape)\n",
    "print(total_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pie_graph\n",
    "plt.figure(1, figsize=(8,8))\n",
    "total_data.age.value_counts().plot.pie(autopct=\"%1.1f%%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar chart\n",
    "gender = ['f','m','u']\n",
    "plt.bar(gender, total_data.gender.value_counts(), align='center', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./AdienceBenchmarkGenderAndAgeClassification/faces/\"+total_data.user_id.loc[0]+\"/coarse_tilt_aligned_face.\"+str(total_data.face_id.loc[0])+\".\"+total_data.original_image.loc[0]\n",
    "img = load_img(path)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = total_data[['age', 'gender', 'x', 'y', 'dx', 'dy']].copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = []\n",
    "for row in total_data.iterrows():\n",
    "    path = \"./AdienceBenchmarkGenderAndAgeClassification/faces/\"+row[1].user_id+\"/coarse_tilt_aligned_face.\"+str(row[1].face_id)+\".\"+row[1].original_image\n",
    "    img_path.append(path)\n",
    "\n",
    "df['img_path'] = img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_mapping = [('(0, 2)', '0-2'), ('2', '0-2'), ('3', '0-2'), ('(4, 6)', '4-6'), ('(8, 12)', '8-13'), ('13', '8-13'), ('22', '15-20'), ('(8, 23)','15-20'), ('23', '25-32'), ('(15, 20)', '15-20'), ('(25, 32)', '25-32'), ('(27, 32)', '25-32'), ('32', '25-32'), ('34', '25-32'), ('29', '25-32'), ('(38, 42)', '38-43'), ('35', '38-43'), ('36', '38-43'), ('42', '48-53'), ('45', '38-43'), ('(38, 43)', '38-43'), ('(38, 42)', '38-43'), ('(38, 48)', '48-53'), ('46', '48-53'), ('(48, 53)', '48-53'), ('55', '48-53'), ('56', '48-53'), ('(60, 100)', '60+'), ('57', '60+'), ('58', '60+')]\n",
    "\n",
    "age_mapping_dict = {each[0]: each[1] for each in age_mapping}\n",
    "drop_labels = []\n",
    "for idx, each in enumerate(df.age):\n",
    "    if each == 'None':\n",
    "        drop_labels.append(idx)\n",
    "    else:\n",
    "        df.age.loc[idx] = age_mapping_dict[each]\n",
    "\n",
    "df = df.drop(labels=drop_labels, axis=0) #droped None values\n",
    "df.age.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "unbiased_data = df[df.gender != 'u'].copy()\n",
    "unbiased_data.info()\n",
    "gender_to_label_map = {\n",
    "    'f' : 0,\n",
    "    'm' : 1\n",
    "}\n",
    "\n",
    "age_to_label_map = {\n",
    "    '0-2'  :0,\n",
    "    '4-6'  :1,\n",
    "    '8-13' :2,\n",
    "    '15-20':3,\n",
    "    '25-32':4,\n",
    "    '38-43':5,\n",
    "    '48-53':6,\n",
    "    '60+'  :7\n",
    "}\n",
    "\n",
    "# label_to_age_map = {value: key for key, value in age_to_label_map.items()}\n",
    "# label_to_gender_map = {value: key for key, value in gender_to_label_map.items()}\n",
    "\n",
    "unbiased_data['age'] = unbiased_data['age'].apply(lambda age: age_to_label_map[age])\n",
    "unbiased_data['gender'] = unbiased_data['gender'].apply(lambda g: gender_to_label_map[g])\n",
    "\n",
    "unbiased_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = unbiased_data[['img_path']]\n",
    "y = unbiased_data[['gender']]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print('Train data shape {}'.format(X_train.shape))\n",
    "print('Test data shape {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "test_images = []\n",
    "\n",
    "for row in X_train.iterrows():\n",
    "    image = Image.open(row[1].img_path)\n",
    "    image = image.resize((227, 227))   # Resize the image\n",
    "    data = np.asarray(image)\n",
    "    train_images.append(data)\n",
    "\n",
    "for row in X_test.iterrows():\n",
    "    image = Image.open(row[1].img_path)\n",
    "    image = image.resize((227, 227))  # Resize the image\n",
    "    data = np.asarray(image)\n",
    "    test_images.append(data)\n",
    "\n",
    "train_images = np.asarray(train_images)\n",
    "test_images = np.asarray(test_images)\n",
    "\n",
    "print('Train images shape {}'.format(train_images.shape))\n",
    "print('Test images shape {}'.format(test_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(227, 227, 3), filters=96, kernel_size=(7, 7), strides=4, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(LayerNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(LayerNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(LayerNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3) # Callback for earlystopping\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "history = model.fit(train_images, y_train, batch_size=32, epochs=5, validation_data=(test_images, y_test), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('gender_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, y_test, verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = unbiased_data[['img_path']]\n",
    "y = unbiased_data[['age']]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print('Train data shape {}'.format(X_train.shape))\n",
    "print('Test data shape {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "test_images = []\n",
    "\n",
    "for row in X_train.iterrows():\n",
    "    image = Image.open(row[1].img_path)\n",
    "    image = image.resize((227, 227))   # Resize the image\n",
    "    data = np.asarray(image)\n",
    "    train_images.append(data)\n",
    "\n",
    "for row in X_test.iterrows():\n",
    "    image = Image.open(row[1].img_path)\n",
    "    image = image.resize((227, 227))  # Resize the image\n",
    "    data = np.asarray(image)\n",
    "    test_images.append(data)\n",
    "\n",
    "train_images = np.asarray(train_images)\n",
    "test_images = np.asarray(test_images)\n",
    "\n",
    "print('Train images shape {}'.format(train_images.shape))\n",
    "print('Test images shape {}'.format(test_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(227, 227, 3), filters=96, kernel_size=(7, 7), strides=4, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(LayerNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(LayerNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(LayerNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3) # Callback for earlystopping\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "history = model.fit(train_images, y_train, batch_size=32, epochs=5, validation_data=(test_images, y_test), callbacks=[callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8a8d7a755f031860a6e8cc6394e373113af13382dba182be7ca4ee8aa60fdd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
